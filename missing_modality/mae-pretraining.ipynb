{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-tCUmKj99CG"
   },
   "source": [
    "# Masked Autoencoders Are Scalable Vision Learners\n",
    "\n",
    "This notebook is a TF2.x implementation of [Masked Autoencoders Are Scalable Vision Learners](https://arxiv.org/abs/2111.06377) by He et. al.\n",
    "\n",
    "The notebook uses the following resource as a reference:\n",
    "\n",
    "- [Image classification with Vision Transformer](https://keras.io/examples/vision/image_classification_with_vision_transformer/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8pvWN_--Veq",
    "tags": []
   },
   "source": [
    "# Import & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "80ZKaTtG9zw9",
    "outputId": "467ea57f-03ac-43d5-e19a-a5a8ac99c393"
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NTZxVZLk-aLN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNM1SbqG-iHN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2qI0r9N_TeW"
   },
   "source": [
    "# Dataset\n",
    "\n",
    "Using **CIFAR10** for our implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lMOYr_h1_QY6",
    "outputId": "e0201dc6-c933-4cf8-c54f-7fde8e3d27de"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sH3ihMqv_Zvn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3jSERWD_dxh"
   },
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6E12LNFc_dm5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dynDm4z6AK-q"
   },
   "source": [
    "# Create Patches\n",
    "\n",
    "This layer creates patches from input images. The layer also consists of two utility methods:\n",
    "- `show_patched_image`: This utility function takes a batch of images and its corresponding patches, randomly choses a pair and plots it. This is useful for a sanity check.\n",
    "- `reconstruct_from_patch`: This utility funciton takes the patches of a **single** image, and reconstructs it back into the original image. This is useful for the training monitor callback defined later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dAiN1D-5AMGg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "id": "ptI3I2aMB_rS",
    "outputId": "895d0714-f9ba-4235-ca8a-b3c21ec7091c"
   },
   "outputs": [],
   "source": [
    "# Get a batch of images.\n",
    "image_batch = next(iter(train_ds))\n",
    "\n",
    "# Augment the images.\n",
    "augmentation_model = get_train_augmentation_model()\n",
    "augmeneted_images = augmentation_model(image_batch)\n",
    "\n",
    "# Define the patch layer.\n",
    "patch_layer = Patches()\n",
    "\n",
    "# Get the patches from the batched images.\n",
    "patches = patch_layer(images=augmeneted_images)\n",
    "\n",
    "# Now pass the images and the corresponding patches\n",
    "# to the `show_patched_image` method.\n",
    "random_index = patch_layer.show_patched_image(images=augmeneted_images, patches=patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "qv0Va_68CPmF",
    "outputId": "5dd6d051-2740-452b-f57c-2131b7b8a3b1"
   },
   "outputs": [],
   "source": [
    "# Chose the same chose image and try reconstructing the patches\n",
    "# into the original image.\n",
    "image = patch_layer.reconstruct_from_patch(patches[random_index])\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GYmyvRZCbL4"
   },
   "source": [
    "# Patch Encoder\n",
    "\n",
    "This layer deals with encoding the pathces and adding the positional embedding too. The layer holds two utility functions:\n",
    "- `get_random_indices`: This function provides randomly sampled mask and unmask indices.\n",
    "- `show_masked_image`: A utility function that plots a random masked image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39WbLUN6CaU9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PvEhNFDcFCLF"
   },
   "outputs": [],
   "source": [
    "# Create the patch encoder layer.\n",
    "patch_encoder = PatchEncoder()\n",
    "\n",
    "# Get the embeddings and positions.\n",
    "(\n",
    "    unmasked_embeddings,\n",
    "    masked_embeddings,\n",
    "    unmasked_positions,\n",
    "    mask_indices,\n",
    "    unmask_indices,\n",
    ") = patch_encoder(patches=patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "UlxangzdFwMJ",
    "outputId": "72caf44d-71d8-4e95-b66d-f4a7a75b0c90"
   },
   "outputs": [],
   "source": [
    "# Show a maksed patch image.\n",
    "new_patch, random_index = patch_encoder.show_masked_image(patches, unmask_indices)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "img = patch_layer.reconstruct_from_patch(new_patch)\n",
    "plt.imshow(keras.utils.array_to_img(img))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Masked\")\n",
    "plt.subplot(1, 2, 2)\n",
    "img = augmeneted_images[random_index]\n",
    "plt.imshow(keras.utils.array_to_img(img))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Original\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A88s55FzF9Rz"
   },
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "91-B5HvSF52o"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_CHs2O1GA8X"
   },
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56BDy60iGB4N"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-r40qxxGOnF"
   },
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4t3AnQ1GN8i"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQ1LwTdlGcuU"
   },
   "source": [
    "# MaskedAutoEncoder Model\n",
    "\n",
    "This is the trainer model where we encapsulate the training logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7-V6L61yGbg6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCOI8_9BX_6g"
   },
   "source": [
    "# Model init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2LqZWL1eHS8l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCDOA_kdX_6h"
   },
   "source": [
    "## Training callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QjuUx4OYHaQx"
   },
   "outputs": [],
   "source": [
    "# Taking a batch of test inputs to measure model's progress.\n",
    "test_images =\n",
    "\n",
    "\n",
    "class TrainMonitor(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,test_ds, epoch_interval=None):\n",
    "        self.epoch_interval = epoch_interval\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.epoch_interval and epoch % self.epoch_interval == 0:\n",
    "            test_augmeneted_images = self.model.test_augmentation_model(next(iter(test_ds)))\n",
    "            test_patches = self.model.patch_layer(test_augmeneted_images)\n",
    "            (\n",
    "                test_unmasked_embeddings,\n",
    "                test_masked_embeddings,\n",
    "                test_unmasked_positions,\n",
    "                test_mask_indices,\n",
    "                test_unmask_indices,\n",
    "            ) = self.model.patch_encoder(test_patches)\n",
    "            test_encoder_outputs = self.model.encoder(test_unmasked_embeddings)\n",
    "            test_encoder_outputs = test_encoder_outputs + test_unmasked_positions\n",
    "            test_decoder_inputs = tf.concat(\n",
    "                [test_encoder_outputs, test_masked_embeddings], axis=1\n",
    "            )\n",
    "            test_decoder_outputs = self.model.decoder(test_decoder_inputs)\n",
    "\n",
    "            # Show a maksed patch image.\n",
    "            test_masked_patch, idx = self.model.patch_encoder.show_masked_image(\n",
    "                test_patches, test_unmask_indices\n",
    "            )\n",
    "            print(f\"\\nIdx chosen: {idx}\")\n",
    "            original_image = test_augmeneted_images[idx]\n",
    "            masked_image = self.model.patch_layer.reconstruct_from_patch(\n",
    "                test_masked_patch\n",
    "            )\n",
    "            reconstructed_image = test_decoder_outputs[idx]\n",
    "\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "            ax[0].imshow(original_image)\n",
    "            ax[0].set_title(f\"Original: {epoch:03d}\")\n",
    "\n",
    "            ax[1].imshow(masked_image)\n",
    "            ax[1].set_title(f\"Masked: {epoch:03d}\")\n",
    "\n",
    "            ax[2].imshow(reconstructed_image)\n",
    "            ax[2].set_title(f\"Resonstructed: {epoch:03d}\")\n",
    "\n",
    "            plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s4PEJxppX_6h"
   },
   "outputs": [],
   "source": [
    "# Some code is taken from:\n",
    "# https://www.kaggle.com/ashusma/training-rfcx-tensorflow-tpu-effnet-b2.\n",
    "\n",
    "\n",
    "class WarmUpCosine(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(\n",
    "        self, learning_rate_base, total_steps, warmup_learning_rate, warmup_steps\n",
    "    ):\n",
    "        super(WarmUpCosine, self).__init__()\n",
    "\n",
    "        self.learning_rate_base = learning_rate_base\n",
    "        self.total_steps = total_steps\n",
    "        self.warmup_learning_rate = warmup_learning_rate\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.pi = tf.constant(np.pi)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        if self.total_steps < self.warmup_steps:\n",
    "            raise ValueError(\"Total_steps must be larger or equal to warmup_steps.\")\n",
    "\n",
    "        cos_annealed_lr = tf.cos(\n",
    "            self.pi\n",
    "            * (tf.cast(step, tf.float32) - self.warmup_steps)\n",
    "            / float(self.total_steps - self.warmup_steps)\n",
    "        )\n",
    "        learning_rate = 0.5 * self.learning_rate_base * (1 + cos_annealed_lr)\n",
    "\n",
    "        if self.warmup_steps > 0:\n",
    "            if self.learning_rate_base < self.warmup_learning_rate:\n",
    "                raise ValueError(\n",
    "                    \"Learning_rate_base must be larger or equal to \"\n",
    "                    \"warmup_learning_rate.\"\n",
    "                )\n",
    "            slope = (\n",
    "                self.learning_rate_base - self.warmup_learning_rate\n",
    "            ) / self.warmup_steps\n",
    "            warmup_rate = slope * tf.cast(step, tf.float32) + self.warmup_learning_rate\n",
    "            learning_rate = tf.where(\n",
    "                step < self.warmup_steps, warmup_rate, learning_rate\n",
    "            )\n",
    "        return tf.where(\n",
    "            step > self.total_steps, 0.0, learning_rate, name=\"learning_rate\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "iTn6VcaBX_6h",
    "outputId": "c0df7a58-763f-4a1f-bbf3-1e1f2e64784f"
   },
   "outputs": [],
   "source": [
    "total_steps = int((len(x_train) / BATCH_SIZE) * EPOCHS)\n",
    "warmup_steps = int(total_steps * 0.15)\n",
    "scheduled_lrs = WarmUpCosine(\n",
    "    learning_rate_base=LEARNING_RATE,\n",
    "    total_steps=total_steps,\n",
    "    warmup_learning_rate=0.0,\n",
    "    warmup_steps=warmup_steps,\n",
    ")\n",
    "\n",
    "lrs = [scheduled_lrs(step) for step in range(total_steps)]\n",
    "plt.plot(lrs)\n",
    "plt.xlabel(\"Step\", fontsize=14)\n",
    "plt.ylabel(\"LR\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_heFaYxJaOp"
   },
   "outputs": [],
   "source": [
    "timestamp = datetime.utcnow().strftime(\"%y%m%d-%H%M%S\")\n",
    "\n",
    "train_callbacks = [\n",
    "    keras.callbacks.TensorBoard(log_dir=f\"mae_logs_{timestamp}\"),\n",
    "    TrainMonitor(epoch_interval=5),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-dUZ1RYqX_6h"
   },
   "source": [
    "# Compilation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtgH-OxyJczw"
   },
   "outputs": [],
   "source": [
    "optimizer = tfa.optimizers.AdamW(learning_rate=scheduled_lrs, weight_decay=WEIGHT_DECAY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZUAXzpDoJiXG",
    "outputId": "2015187b-0bfb-445e-a687-018a9284a649"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S0aVUm63Lj-L",
    "outputId": "cbe80727-6cc3-4db3-ec5d-cf01469f38d0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8mJ1QkHLoPd"
   },
   "source": [
    "# Downstrean Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kXnO5jNALndF",
    "outputId": "8b6c45a7-10bf-4e58-f866-f691b5352b12"
   },
   "outputs": [],
   "source": [
    "# Extract the augmentation layers.\n",
    "train_augmentation_model = mae_model.train_augmentation_model\n",
    "test_augmentation_model = mae_model.test_augmentation_model\n",
    "\n",
    "# Extract the patchers.\n",
    "patch_layer = mae_model.patch_layer\n",
    "patch_encoder = mae_model.patch_encoder\n",
    "patch_encoder.downstream = True  # Swtich the downstream flag to True.\n",
    "\n",
    "# Extract the encoder.\n",
    "encoder = mae_model.encoder\n",
    "\n",
    "# Pack as a model.\n",
    "downstream_model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input((IMAGE_SIZE, IMAGE_SIZE, 3)),\n",
    "        patch_layer,\n",
    "        patch_encoder,\n",
    "        encoder,\n",
    "        layers.BatchNormalization(),  # Refer to A.1 (Linear probing)\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "        layers.Dense(NUM_CLASSES, activation=\"softmax\"),\n",
    "    ],\n",
    "    name=\"linear_probe_model\",\n",
    ")\n",
    "\n",
    "# Only the final classification layer of the `downstream_model` should be trainable.\n",
    "for layer in downstream_model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "downstream_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oPaNGdfvLtyR"
   },
   "outputs": [],
   "source": [
    "def prepare_data(images, labels, is_train=True):\n",
    "    if is_train:\n",
    "        augmentation_model = train_augmentation_model\n",
    "    else:\n",
    "        augmentation_model = test_augmentation_model\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    if is_train:\n",
    "\n",
    "    return dataset.prefetch(AUTO)\n",
    "\n",
    "\n",
    "train_ds = prepare_data(x_train, y_train)\n",
    "val_ds = prepare_data(x_train, y_train, is_train=False)\n",
    "test_ds = prepare_data(x_test, y_test, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xdeuZ98oLvis",
    "outputId": "c9f7b566-47e9-4afa-a86d-728df915cd99"
   },
   "outputs": [],
   "source": [
    "linear_probe_epochs = 50\n",
    "linear_prob_lr = 0.1\n",
    "warm_epoch_percentage = 0.1\n",
    "steps = int((len(x_train) // BATCH_SIZE) * linear_probe_epochs)\n",
    "\n",
    "warmup_steps = int(steps * warm_epoch_percentage)\n",
    "scheduled_lrs = WarmUpCosine(\n",
    "    learning_rate_base=linear_prob_lr,\n",
    "    total_steps=steps,\n",
    "    warmup_learning_rate=0.0,\n",
    "    warmup_steps=warmup_steps,\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=scheduled_lrs, momentum=0.9)\n",
    "downstream_model.compile(\n",
    "    optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "downstream_model.fit(train_ds, validation_data=val_ds, epochs=linear_probe_epochs)\n",
    "\n",
    "loss, accuracy = downstream_model.evaluate(test_ds)\n",
    "accuracy = round(accuracy * 100, 2)\n",
    "print(f\"Accuracy on the test set: {accuracy}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0o8DHVfAMrSL",
    "outputId": "c98b307d-c002-4507-ac21-0ca777cf3f06"
   },
   "outputs": [],
   "source": [
    "downstream_model.save(f\"linear_probe_{timestamp}\", include_optimizer=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "mae-pretraining.ipynb",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m84",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m84"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
