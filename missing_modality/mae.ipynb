{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NTZxVZLk-aLN",
    "ExecuteTime": {
     "end_time": "2023-06-26T19:40:14.686587900Z",
     "start_time": "2023-06-26T19:40:11.750828500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python38\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2qI0r9N_TeW"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T19:49:24.750881600Z",
     "start_time": "2023-06-26T19:49:02.341227Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamed\\AppData\\Local\\Temp\\ipykernel_18716\\3189862859.py:4: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  xx[i, :, :, 0] = Zxx\n"
     ]
    }
   ],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T19:49:27.897010Z",
     "start_time": "2023-06-26T19:49:27.584753400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(1396, 129, 31, 1)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T19:49:44.421356800Z",
     "start_time": "2023-06-26T19:49:44.405753900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2LqZWL1eHS8l",
    "ExecuteTime": {
     "end_time": "2023-06-26T19:50:26.923040700Z",
     "start_time": "2023-06-26T19:50:23.938416800Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCDOA_kdX_6h"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "iTn6VcaBX_6h",
    "outputId": "c0df7a58-763f-4a1f-bbf3-1e1f2e64784f",
    "ExecuteTime": {
     "end_time": "2023-06-26T19:50:28.310107Z",
     "start_time": "2023-06-26T19:50:27.973077200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 129, 31, 1) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 129, 31, 1) dtype=float32>). Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\PycharmProjects\\Pediatric-Apnea-Transformer\\missing_modality\\model.py\", line 139, in train_step\n        total_loss, loss_patch, loss_output = self.calculate_loss(images)\n    File \"C:\\PycharmProjects\\Pediatric-Apnea-Transformer\\missing_modality\\model.py\", line 104, in calculate_loss\n        augmeneted_images = self.train_augmentation_model(images)\n    File \"c:\\python\\python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"resizing\" \"                 f\"(type Resizing).\n    \n    'images' must have either 3 or 4 dimensions.\n    \n    Call arguments received by layer \"resizing\" \"                 f\"(type Resizing):\n      â€¢ inputs=('tf.Tensor(shape=(None, 129, 31, 1), dtype=float32)', 'tf.Tensor(shape=(None, 129, 31, 1), dtype=float32)')\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 15\u001B[0m\n\u001B[0;32m     12\u001B[0m mae_model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, loss\u001B[38;5;241m=\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlosses\u001B[38;5;241m.\u001B[39mMeanSquaredError(), metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmae\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# mae_model.build(input_shape=(None, IMAGE_SIZE, IMAGE_SIZE, 3), output_shape=(None, IMAGE_SIZE, IMAGE_SIZE, 3))\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# mae_model.summary()\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmae_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mxx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mxx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mEPOCHS\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m#  , validation_data=val_ds, callbacks=train_callbacks, )\u001B[39;00m\n",
      "File \u001B[1;32mc:\\python\\python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filexx4tj5xq.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32mC:\\PycharmProjects\\Pediatric-Apnea-Transformer\\missing_modality\\model.py:139\u001B[0m, in \u001B[0;36mMaskedAutoencoder.train_step\u001B[1;34m(self, images)\u001B[0m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_step\u001B[39m(\u001B[38;5;28mself\u001B[39m, images):\n\u001B[0;32m    138\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mGradientTape() \u001B[38;5;28;01mas\u001B[39;00m tape:\n\u001B[1;32m--> 139\u001B[0m         total_loss, loss_patch, loss_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcalculate_loss(images)\n\u001B[0;32m    141\u001B[0m     \u001B[38;5;66;03m# Apply gradients.\u001B[39;00m\n\u001B[0;32m    142\u001B[0m     train_vars \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    143\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_augmentation_model\u001B[38;5;241m.\u001B[39mtrainable_variables,\n\u001B[0;32m    144\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpatch_layer\u001B[38;5;241m.\u001B[39mtrainable_variables,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    147\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder\u001B[38;5;241m.\u001B[39mtrainable_variables,\n\u001B[0;32m    148\u001B[0m     ]\n",
      "File \u001B[1;32mC:\\PycharmProjects\\Pediatric-Apnea-Transformer\\missing_modality\\model.py:104\u001B[0m, in \u001B[0;36mMaskedAutoencoder.calculate_loss\u001B[1;34m(self, images, test)\u001B[0m\n\u001B[0;32m    102\u001B[0m     augmeneted_images \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtest_augmentation_model(images)\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 104\u001B[0m     augmeneted_images \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_augmentation_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    106\u001B[0m \u001B[38;5;66;03m# Patch the augmented images.\u001B[39;00m\n\u001B[0;32m    107\u001B[0m patches \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpatch_layer(augmeneted_images)\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"c:\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\PycharmProjects\\Pediatric-Apnea-Transformer\\missing_modality\\model.py\", line 139, in train_step\n        total_loss, loss_patch, loss_output = self.calculate_loss(images)\n    File \"C:\\PycharmProjects\\Pediatric-Apnea-Transformer\\missing_modality\\model.py\", line 104, in calculate_loss\n        augmeneted_images = self.train_augmentation_model(images)\n    File \"c:\\python\\python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"resizing\" \"                 f\"(type Resizing).\n    \n    'images' must have either 3 or 4 dimensions.\n    \n    Call arguments received by layer \"resizing\" \"                 f\"(type Resizing):\n      â€¢ inputs=('tf.Tensor(shape=(None, 129, 31, 1), dtype=float32)', 'tf.Tensor(shape=(None, 129, 31, 1), dtype=float32)')\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S0aVUm63Lj-L",
    "outputId": "cbe80727-6cc3-4db3-ec5d-cf01469f38d0",
    "ExecuteTime": {
     "end_time": "2023-06-23T16:47:53.473766400Z",
     "start_time": "2023-06-23T16:47:52.734057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 17ms/step - loss: 0.0201 - mae: 0.1032\n",
      "Loss: 0.02\n",
      "MAE: 0.10\n"
     ]
    }
   ],
   "source": [
    "loss, mae = mae_model.evaluate(train_ds)\n",
    "print(f\"Loss: {loss:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8mJ1QkHLoPd"
   },
   "source": [
    "# Downstrean Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kXnO5jNALndF",
    "outputId": "8b6c45a7-10bf-4e58-f866-f691b5352b12",
    "ExecuteTime": {
     "end_time": "2023-06-23T16:47:53.696530900Z",
     "start_time": "2023-06-23T16:47:53.473766400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"linear_probe_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " patches_pre (PatchesPre)    (None, 64, 108)           0         \n",
      "                                                                 \n",
      " patch_encoder_pre (PatchEnc  (None, 64, 128)          22252     \n",
      " oderPre)                                                        \n",
      "                                                                 \n",
      " mae_encoder (Functional)    (None, None, 128)         990976    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64, 128)          512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,015,030\n",
      "Trainable params: 1,290\n",
      "Non-trainable params: 1,013,740\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Extract the augmentation layers.\n",
    "train_augmentation_model = mae_model.train_augmentation_model\n",
    "test_augmentation_model = mae_model.test_augmentation_model\n",
    "# Extract the patchers.\n",
    "patch_layer = mae_model.patch_layer\n",
    "patch_encoder = mae_model.patch_encoder\n",
    "patch_encoder.downstream = True  # Swtich the downstream flag to True.\n",
    "# Extract the encoder.\n",
    "encoder = mae_model.encoder\n",
    "# Pack as a model.\n",
    "downstream_model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input((IMAGE_SIZE, IMAGE_SIZE, 3)),\n",
    "        patch_layer,\n",
    "        patch_encoder,\n",
    "        encoder,\n",
    "        layers.BatchNormalization(),  # Refer to A.1 (Linear probing)\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "        layers.Dense(NUM_CLASSES, activation=\"softmax\"),\n",
    "    ],\n",
    "    name=\"linear_probe_model\",\n",
    ")\n",
    "\n",
    "# Only the final classification layer of the `downstream_model` should be trainable.\n",
    "for layer in downstream_model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "downstream_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oPaNGdfvLtyR",
    "ExecuteTime": {
     "end_time": "2023-06-23T16:47:54.326350800Z",
     "start_time": "2023-06-23T16:47:53.706541400Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = prepare_data(x_train, y_train)\n",
    "val_ds = prepare_data(x_train, y_train, is_train=False)\n",
    "test_ds = prepare_data(x_test, y_test, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xdeuZ98oLvis",
    "outputId": "c9f7b566-47e9-4afa-a86d-728df915cd99",
    "ExecuteTime": {
     "end_time": "2023-06-23T16:48:38.553880600Z",
     "start_time": "2023-06-23T16:47:54.326350800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "157/157 [==============================] - 10s 54ms/step - loss: 1.9531 - accuracy: 0.3090 - val_loss: 1.8220 - val_accuracy: 0.3513\n",
      "Epoch 2/5\n",
      "157/157 [==============================] - 8s 50ms/step - loss: 1.7902 - accuracy: 0.3605 - val_loss: 1.7597 - val_accuracy: 0.3692\n",
      "Epoch 3/5\n",
      "157/157 [==============================] - 9s 54ms/step - loss: 1.7448 - accuracy: 0.3782 - val_loss: 1.7036 - val_accuracy: 0.3939\n",
      "Epoch 4/5\n",
      "157/157 [==============================] - 8s 52ms/step - loss: 1.7129 - accuracy: 0.3945 - val_loss: 1.6764 - val_accuracy: 0.4105\n",
      "Epoch 5/5\n",
      "157/157 [==============================] - 8s 52ms/step - loss: 1.6996 - accuracy: 0.4003 - val_loss: 1.6735 - val_accuracy: 0.4133\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 1.6721 - accuracy: 0.4111\n",
      "Accuracy on the test set: 41.11%.\n"
     ]
    }
   ],
   "source": [
    "linear_probe_epochs = 5  #TODO: 20\n",
    "linear_prob_lr = 0.1\n",
    "warm_epoch_percentage = 0.1\n",
    "steps = int((len(x_train) // BATCH_SIZE) * linear_probe_epochs)\n",
    "\n",
    "warmup_steps = int(steps * warm_epoch_percentage)\n",
    "scheduled_lrs = WarmUpCosine(learning_rate_base=linear_prob_lr, total_steps=steps, warmup_learning_rate=0.0,\n",
    "                             warmup_steps=warmup_steps, )\n",
    "optimizer = keras.optimizers.SGD(learning_rate=scheduled_lrs, momentum=0.9)\n",
    "downstream_model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "downstream_model.fit(train_ds, validation_data=val_ds, epochs=linear_probe_epochs)\n",
    "\n",
    "loss, accuracy = downstream_model.evaluate(test_ds)\n",
    "accuracy = round(accuracy * 100, 2)\n",
    "print(f\"Accuracy on the test set: {accuracy}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0o8DHVfAMrSL",
    "outputId": "c98b307d-c002-4507-ac21-0ca777cf3f06",
    "ExecuteTime": {
     "end_time": "2023-06-23T16:48:43.368484400Z",
     "start_time": "2023-06-23T16:48:38.555161600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as reshape_layer_call_fn, reshape_layer_call_and_return_conditional_losses, dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, embedding_layer_call_fn while saving (showing 5 of 42). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: linear_probe_230623-164625\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: linear_probe_230623-164625\\assets\n"
     ]
    }
   ],
   "source": [
    "downstream_model.save(f\"linear_probe_{timestamp}\", include_optimizer=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "mae-pretraining.ipynb",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m84",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m84"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
